{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VtQo-PANT-VQ",
        "outputId": "d12aec0e-f812-4d2b-9426-0270ec5d8407"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello\n"
          ]
        }
      ],
      "source": [
        "print(\"Hello\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "B109110301 張晉霖 CIFAR-100 實作"
      ],
      "metadata": {
        "id": "evwylYyjrm23"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets import cifar100"
      ],
      "metadata": {
        "id": "rR_nQAFwVpdA"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load CIFAR-100 data\n",
        "(input_train, target_train), (input_test, target_test) = cifar100.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "bpVfoX52VwCz",
        "outputId": "c55f9237-1a90-4903-8577-c37dfe5d553f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
            "169001437/169001437 [==============================] - 6s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.pooling import MaxPool2D\n",
        "from keras.layers.core import Dense,Activation,Dropout,Flatten\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.initializers import RandomNormal, Constant\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Model configuration\n",
        "batch_size = 64\n",
        "img_width, img_height, img_num_channels = 32, 32, 3\n",
        "\n",
        "no_classes = 100\n",
        "no_epochs = 350\n",
        "validation_split = 0.2\n",
        "verbosity = 1\n",
        "\n",
        "# Load CIFAR-100 data\n",
        "(input_train, target_train), (input_test, target_test) = cifar100.load_data()\n",
        "\n",
        "# Determine shape of the data\n",
        "input_shape = (img_width, img_height, img_num_channels)\n",
        "\n",
        "# Parse numbers as floats\n",
        "input_train = input_train.astype('float32')\n",
        "input_test = input_test.astype('float32')\n",
        "train_images = input_train.astype('float32')/255\n",
        "test_images = input_test.astype('float32')/255\n",
        "\n",
        "# Normalize data\n",
        "input_train = input_train / 255\n",
        "input_test = input_test / 255\n",
        "\n",
        "\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "train_labels = to_categorical(target_train)\n",
        "test_labels = to_categorical(target_test)\n",
        "\n",
        "# Create the model\n",
        "model = Sequential()\n",
        " \n",
        "model.add(Conv2D(256,(3,3),padding='same',input_shape=(32,32,3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(256,(3,3),padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPool2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.2))\n",
        " \n",
        "model.add(Conv2D(512,(3,3),padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(512,(3,3),padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPool2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Conv2D(512,(3,3),padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(512,(3,3),padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPool2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Conv2D(512,(3,3),padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(512,(3,3),padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPool2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1024))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(BatchNormalization(momentum=0.95, \n",
        "        epsilon=0.005,\n",
        "        beta_initializer=RandomNormal(mean=0.0, stddev=0.05), \n",
        "        gamma_initializer=Constant(value=0.9)))\n",
        "model.add(Dense(100,activation='softmax'))\n",
        "model.summary()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Configuration for creating new images\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    horizontal_flip=True,\n",
        ")\n",
        "\n",
        "input_train, input_validation, target_train, target_validation = train_test_split(train_images, train_labels, test_size=0.2, random_state=93)\n",
        "train_datagen.fit(input_train)\n",
        "     \n",
        "\n",
        "# Configure the model for training\n",
        "from tensorflow.keras import optimizers\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizers.RMSprop(learning_rate=1e-4),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Fit data to model\n",
        "history = model.fit(train_datagen.flow(input_train, target_train,\n",
        "            batch_size=batch_size),\n",
        "            steps_per_epoch=100,\n",
        "            epochs=no_epochs,\n",
        "            verbose=verbosity,\n",
        "            validation_data=(input_validation, target_validation))\n",
        "\n",
        "# Generate generalization metrics\n",
        "score = model.evaluate(test_images, test_labels)\n",
        "print(f'accuracy on test set: {model.metrics_names[1]} of {score[1]*100}')\n",
        "\n",
        "# Visualize history\n",
        "# Plot history: Loss\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Validation loss history')\n",
        "plt.ylabel('Loss value')\n",
        "plt.xlabel('No. epoch')\n",
        "plt.show()\n",
        "\n",
        "# Plot history: Accuracy\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Validation accuracy history')\n",
        "plt.ylabel('Accuracy value (%)')\n",
        "plt.xlabel('No. epoch')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 14459
        },
        "id": "Arcl2_PiV3PU",
        "outputId": "2a3deabb-3bbf-40fc-f26b-a7f8bfeb9c36"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_24 (Conv2D)          (None, 32, 32, 256)       7168      \n",
            "                                                                 \n",
            " batch_normalization_27 (Bat  (None, 32, 32, 256)      1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_27 (Activation)  (None, 32, 32, 256)       0         \n",
            "                                                                 \n",
            " conv2d_25 (Conv2D)          (None, 32, 32, 256)       590080    \n",
            "                                                                 \n",
            " batch_normalization_28 (Bat  (None, 32, 32, 256)      1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_28 (Activation)  (None, 32, 32, 256)       0         \n",
            "                                                                 \n",
            " max_pooling2d_12 (MaxPoolin  (None, 16, 16, 256)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_15 (Dropout)        (None, 16, 16, 256)       0         \n",
            "                                                                 \n",
            " conv2d_26 (Conv2D)          (None, 16, 16, 512)       1180160   \n",
            "                                                                 \n",
            " batch_normalization_29 (Bat  (None, 16, 16, 512)      2048      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_29 (Activation)  (None, 16, 16, 512)       0         \n",
            "                                                                 \n",
            " conv2d_27 (Conv2D)          (None, 16, 16, 512)       2359808   \n",
            "                                                                 \n",
            " batch_normalization_30 (Bat  (None, 16, 16, 512)      2048      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_30 (Activation)  (None, 16, 16, 512)       0         \n",
            "                                                                 \n",
            " max_pooling2d_13 (MaxPoolin  (None, 8, 8, 512)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_16 (Dropout)        (None, 8, 8, 512)         0         \n",
            "                                                                 \n",
            " conv2d_28 (Conv2D)          (None, 8, 8, 512)         2359808   \n",
            "                                                                 \n",
            " batch_normalization_31 (Bat  (None, 8, 8, 512)        2048      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_31 (Activation)  (None, 8, 8, 512)         0         \n",
            "                                                                 \n",
            " conv2d_29 (Conv2D)          (None, 8, 8, 512)         2359808   \n",
            "                                                                 \n",
            " batch_normalization_32 (Bat  (None, 8, 8, 512)        2048      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_32 (Activation)  (None, 8, 8, 512)         0         \n",
            "                                                                 \n",
            " max_pooling2d_14 (MaxPoolin  (None, 4, 4, 512)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_17 (Dropout)        (None, 4, 4, 512)         0         \n",
            "                                                                 \n",
            " conv2d_30 (Conv2D)          (None, 4, 4, 512)         2359808   \n",
            "                                                                 \n",
            " batch_normalization_33 (Bat  (None, 4, 4, 512)        2048      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_33 (Activation)  (None, 4, 4, 512)         0         \n",
            "                                                                 \n",
            " conv2d_31 (Conv2D)          (None, 4, 4, 512)         2359808   \n",
            "                                                                 \n",
            " batch_normalization_34 (Bat  (None, 4, 4, 512)        2048      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_34 (Activation)  (None, 4, 4, 512)         0         \n",
            "                                                                 \n",
            " max_pooling2d_15 (MaxPoolin  (None, 2, 2, 512)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_18 (Dropout)        (None, 2, 2, 512)         0         \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 2048)              0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 1024)              2098176   \n",
            "                                                                 \n",
            " activation_35 (Activation)  (None, 1024)              0         \n",
            "                                                                 \n",
            " dropout_19 (Dropout)        (None, 1024)              0         \n",
            "                                                                 \n",
            " batch_normalization_35 (Bat  (None, 1024)             4096      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 100)               102500    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 15,795,556\n",
            "Trainable params: 15,786,340\n",
            "Non-trainable params: 9,216\n",
            "_________________________________________________________________\n",
            "Epoch 1/350\n",
            "100/100 [==============================] - 23s 211ms/step - loss: 4.6901 - accuracy: 0.0311 - val_loss: 4.7718 - val_accuracy: 0.0086\n",
            "Epoch 2/350\n",
            "100/100 [==============================] - 21s 210ms/step - loss: 4.2707 - accuracy: 0.0698 - val_loss: 5.0850 - val_accuracy: 0.0140\n",
            "Epoch 3/350\n",
            "100/100 [==============================] - 16s 156ms/step - loss: 4.0459 - accuracy: 0.0959 - val_loss: 5.6006 - val_accuracy: 0.0232\n",
            "Epoch 4/350\n",
            "100/100 [==============================] - 15s 155ms/step - loss: 3.9145 - accuracy: 0.1122 - val_loss: 5.4463 - val_accuracy: 0.0267\n",
            "Epoch 5/350\n",
            "100/100 [==============================] - 20s 205ms/step - loss: 3.7611 - accuracy: 0.1300 - val_loss: 4.5966 - val_accuracy: 0.0512\n",
            "Epoch 6/350\n",
            "100/100 [==============================] - 16s 157ms/step - loss: 3.6339 - accuracy: 0.1503 - val_loss: 3.9753 - val_accuracy: 0.1072\n",
            "Epoch 7/350\n",
            "100/100 [==============================] - 16s 159ms/step - loss: 3.5826 - accuracy: 0.1608 - val_loss: 3.7499 - val_accuracy: 0.1322\n",
            "Epoch 8/350\n",
            "100/100 [==============================] - 16s 156ms/step - loss: 3.4679 - accuracy: 0.1755 - val_loss: 3.3880 - val_accuracy: 0.1919\n",
            "Epoch 9/350\n",
            "100/100 [==============================] - 20s 205ms/step - loss: 3.3687 - accuracy: 0.1920 - val_loss: 3.3126 - val_accuracy: 0.2044\n",
            "Epoch 10/350\n",
            "100/100 [==============================] - 20s 205ms/step - loss: 3.3037 - accuracy: 0.1937 - val_loss: 3.2524 - val_accuracy: 0.2209\n",
            "Epoch 11/350\n",
            "100/100 [==============================] - 16s 157ms/step - loss: 3.2104 - accuracy: 0.2245 - val_loss: 3.1069 - val_accuracy: 0.2403\n",
            "Epoch 12/350\n",
            "100/100 [==============================] - 16s 162ms/step - loss: 3.1306 - accuracy: 0.2369 - val_loss: 3.0914 - val_accuracy: 0.2499\n",
            "Epoch 13/350\n",
            "100/100 [==============================] - 21s 206ms/step - loss: 3.0487 - accuracy: 0.2466 - val_loss: 2.9463 - val_accuracy: 0.2740\n",
            "Epoch 14/350\n",
            "100/100 [==============================] - 16s 155ms/step - loss: 2.9547 - accuracy: 0.2644 - val_loss: 3.1330 - val_accuracy: 0.2556\n",
            "Epoch 15/350\n",
            "100/100 [==============================] - 16s 157ms/step - loss: 2.9462 - accuracy: 0.2692 - val_loss: 2.9057 - val_accuracy: 0.2811\n",
            "Epoch 16/350\n",
            "100/100 [==============================] - 16s 162ms/step - loss: 2.8539 - accuracy: 0.2800 - val_loss: 2.8257 - val_accuracy: 0.2883\n",
            "Epoch 17/350\n",
            "100/100 [==============================] - 16s 157ms/step - loss: 2.8148 - accuracy: 0.2994 - val_loss: 2.9307 - val_accuracy: 0.2917\n",
            "Epoch 18/350\n",
            "100/100 [==============================] - 16s 155ms/step - loss: 2.7075 - accuracy: 0.3122 - val_loss: 2.8461 - val_accuracy: 0.2986\n",
            "Epoch 19/350\n",
            "100/100 [==============================] - 16s 157ms/step - loss: 2.6947 - accuracy: 0.3200 - val_loss: 2.6946 - val_accuracy: 0.3169\n",
            "Epoch 20/350\n",
            "100/100 [==============================] - 16s 157ms/step - loss: 2.5616 - accuracy: 0.3481 - val_loss: 2.5240 - val_accuracy: 0.3505\n",
            "Epoch 21/350\n",
            "100/100 [==============================] - 20s 205ms/step - loss: 2.5764 - accuracy: 0.3439 - val_loss: 2.5974 - val_accuracy: 0.3408\n",
            "Epoch 22/350\n",
            "100/100 [==============================] - 16s 157ms/step - loss: 2.4530 - accuracy: 0.3673 - val_loss: 2.8857 - val_accuracy: 0.2951\n",
            "Epoch 23/350\n",
            "100/100 [==============================] - 16s 159ms/step - loss: 2.4141 - accuracy: 0.3758 - val_loss: 2.5056 - val_accuracy: 0.3544\n",
            "Epoch 24/350\n",
            "100/100 [==============================] - 16s 157ms/step - loss: 2.3663 - accuracy: 0.3834 - val_loss: 2.6435 - val_accuracy: 0.3384\n",
            "Epoch 25/350\n",
            "100/100 [==============================] - 16s 157ms/step - loss: 2.3704 - accuracy: 0.3819 - val_loss: 2.3552 - val_accuracy: 0.3901\n",
            "Epoch 26/350\n",
            "100/100 [==============================] - 16s 156ms/step - loss: 2.3367 - accuracy: 0.3914 - val_loss: 2.4414 - val_accuracy: 0.3730\n",
            "Epoch 27/350\n",
            "100/100 [==============================] - 16s 156ms/step - loss: 2.2813 - accuracy: 0.4052 - val_loss: 2.4108 - val_accuracy: 0.3798\n",
            "Epoch 28/350\n",
            "100/100 [==============================] - 16s 156ms/step - loss: 2.2640 - accuracy: 0.4081 - val_loss: 2.7681 - val_accuracy: 0.3320\n",
            "Epoch 29/350\n",
            "100/100 [==============================] - 16s 157ms/step - loss: 2.2031 - accuracy: 0.4186 - val_loss: 2.2790 - val_accuracy: 0.4003\n",
            "Epoch 30/350\n",
            "100/100 [==============================] - 16s 158ms/step - loss: 2.2126 - accuracy: 0.4234 - val_loss: 2.4683 - val_accuracy: 0.3654\n",
            "Epoch 31/350\n",
            "100/100 [==============================] - 16s 156ms/step - loss: 2.1672 - accuracy: 0.4314 - val_loss: 2.2515 - val_accuracy: 0.4143\n",
            "Epoch 32/350\n",
            "100/100 [==============================] - 16s 157ms/step - loss: 2.0922 - accuracy: 0.4475 - val_loss: 2.2772 - val_accuracy: 0.4065\n",
            "Epoch 33/350\n",
            "100/100 [==============================] - 16s 157ms/step - loss: 2.1251 - accuracy: 0.4314 - val_loss: 2.1377 - val_accuracy: 0.4291\n",
            "Epoch 34/350\n",
            "100/100 [==============================] - 20s 206ms/step - loss: 2.0516 - accuracy: 0.4517 - val_loss: 2.4203 - val_accuracy: 0.3853\n",
            "Epoch 35/350\n",
            "100/100 [==============================] - 16s 156ms/step - loss: 2.0762 - accuracy: 0.4481 - val_loss: 2.3480 - val_accuracy: 0.3902\n",
            "Epoch 36/350\n",
            "100/100 [==============================] - 16s 158ms/step - loss: 1.9957 - accuracy: 0.4672 - val_loss: 2.4071 - val_accuracy: 0.3958\n",
            "Epoch 37/350\n",
            "100/100 [==============================] - 16s 156ms/step - loss: 1.9683 - accuracy: 0.4717 - val_loss: 2.2041 - val_accuracy: 0.4211\n",
            "Epoch 38/350\n",
            "100/100 [==============================] - 16s 157ms/step - loss: 1.9631 - accuracy: 0.4809 - val_loss: 2.2104 - val_accuracy: 0.4265\n",
            "Epoch 39/350\n",
            "100/100 [==============================] - 16s 158ms/step - loss: 1.9381 - accuracy: 0.4703 - val_loss: 2.1017 - val_accuracy: 0.4431\n",
            "Epoch 40/350\n",
            "100/100 [==============================] - 16s 156ms/step - loss: 1.9026 - accuracy: 0.4900 - val_loss: 2.3858 - val_accuracy: 0.4035\n",
            "Epoch 41/350\n",
            "100/100 [==============================] - 21s 206ms/step - loss: 1.9250 - accuracy: 0.4831 - val_loss: 2.1668 - val_accuracy: 0.4352\n",
            "Epoch 42/350\n",
            "100/100 [==============================] - 16s 158ms/step - loss: 1.8484 - accuracy: 0.5056 - val_loss: 1.9471 - val_accuracy: 0.4807\n",
            "Epoch 43/350\n",
            "100/100 [==============================] - 16s 160ms/step - loss: 1.8173 - accuracy: 0.5055 - val_loss: 1.9793 - val_accuracy: 0.4677\n",
            "Epoch 44/350\n",
            "100/100 [==============================] - 21s 206ms/step - loss: 1.7906 - accuracy: 0.5095 - val_loss: 2.1680 - val_accuracy: 0.4379\n",
            "Epoch 45/350\n",
            "100/100 [==============================] - 20s 205ms/step - loss: 1.7828 - accuracy: 0.5155 - val_loss: 1.9042 - val_accuracy: 0.4831\n",
            "Epoch 46/350\n",
            "100/100 [==============================] - 16s 157ms/step - loss: 1.7523 - accuracy: 0.5203 - val_loss: 2.1480 - val_accuracy: 0.4381\n",
            "Epoch 47/350\n",
            "100/100 [==============================] - 21s 206ms/step - loss: 1.7203 - accuracy: 0.5303 - val_loss: 1.9540 - val_accuracy: 0.4749\n",
            "Epoch 48/350\n",
            "100/100 [==============================] - 16s 157ms/step - loss: 1.7240 - accuracy: 0.5264 - val_loss: 2.2128 - val_accuracy: 0.4321\n",
            "Epoch 49/350\n",
            "100/100 [==============================] - 16s 156ms/step - loss: 1.6981 - accuracy: 0.5380 - val_loss: 1.9156 - val_accuracy: 0.4836\n",
            "Epoch 50/350\n",
            "100/100 [==============================] - 16s 156ms/step - loss: 1.6888 - accuracy: 0.5417 - val_loss: 2.1395 - val_accuracy: 0.4531\n",
            "Epoch 51/350\n",
            "100/100 [==============================] - 20s 205ms/step - loss: 1.6759 - accuracy: 0.5377 - val_loss: 1.9496 - val_accuracy: 0.4835\n",
            "Epoch 52/350\n",
            "100/100 [==============================] - 16s 156ms/step - loss: 1.6352 - accuracy: 0.5516 - val_loss: 1.8431 - val_accuracy: 0.5044\n",
            "Epoch 53/350\n",
            "100/100 [==============================] - 16s 161ms/step - loss: 1.6270 - accuracy: 0.5536 - val_loss: 1.9587 - val_accuracy: 0.4822\n",
            "Epoch 54/350\n",
            "100/100 [==============================] - 16s 159ms/step - loss: 1.6262 - accuracy: 0.5555 - val_loss: 1.8583 - val_accuracy: 0.5075\n",
            "Epoch 55/350\n",
            "100/100 [==============================] - 20s 205ms/step - loss: 1.6231 - accuracy: 0.5552 - val_loss: 1.8518 - val_accuracy: 0.5062\n",
            "Epoch 56/350\n",
            "100/100 [==============================] - 21s 206ms/step - loss: 1.5906 - accuracy: 0.5617 - val_loss: 2.1402 - val_accuracy: 0.4629\n",
            "Epoch 57/350\n",
            "100/100 [==============================] - 16s 160ms/step - loss: 1.5770 - accuracy: 0.5598 - val_loss: 1.8615 - val_accuracy: 0.5048\n",
            "Epoch 58/350\n",
            "100/100 [==============================] - 21s 206ms/step - loss: 1.5247 - accuracy: 0.5813 - val_loss: 1.7342 - val_accuracy: 0.5313\n",
            "Epoch 59/350\n",
            "100/100 [==============================] - 16s 156ms/step - loss: 1.5544 - accuracy: 0.5683 - val_loss: 1.8844 - val_accuracy: 0.4975\n",
            "Epoch 60/350\n",
            "100/100 [==============================] - 16s 157ms/step - loss: 1.5442 - accuracy: 0.5702 - val_loss: 1.7158 - val_accuracy: 0.5352\n",
            "Epoch 61/350\n",
            "100/100 [==============================] - 16s 156ms/step - loss: 1.5186 - accuracy: 0.5773 - val_loss: 1.8292 - val_accuracy: 0.5096\n",
            "Epoch 62/350\n",
            "100/100 [==============================] - 16s 157ms/step - loss: 1.4648 - accuracy: 0.6016 - val_loss: 2.0238 - val_accuracy: 0.4798\n",
            "Epoch 63/350\n",
            "100/100 [==============================] - 20s 205ms/step - loss: 1.4996 - accuracy: 0.5763 - val_loss: 1.7120 - val_accuracy: 0.5416\n",
            "Epoch 64/350\n",
            "100/100 [==============================] - 16s 157ms/step - loss: 1.4316 - accuracy: 0.5977 - val_loss: 1.8164 - val_accuracy: 0.5122\n",
            "Epoch 65/350\n",
            "100/100 [==============================] - 16s 158ms/step - loss: 1.4443 - accuracy: 0.5958 - val_loss: 1.7278 - val_accuracy: 0.5264\n",
            "Epoch 66/350\n",
            "100/100 [==============================] - 16s 157ms/step - loss: 1.4532 - accuracy: 0.5938 - val_loss: 1.8126 - val_accuracy: 0.5166\n",
            "Epoch 67/350\n",
            "100/100 [==============================] - 16s 156ms/step - loss: 1.4356 - accuracy: 0.5961 - val_loss: 2.0687 - val_accuracy: 0.4783\n",
            "Epoch 68/350\n",
            "100/100 [==============================] - 21s 206ms/step - loss: 1.4076 - accuracy: 0.6034 - val_loss: 1.7432 - val_accuracy: 0.5373\n",
            "Epoch 69/350\n",
            "100/100 [==============================] - 20s 205ms/step - loss: 1.4169 - accuracy: 0.6081 - val_loss: 1.8103 - val_accuracy: 0.5189\n",
            "Epoch 70/350\n",
            "100/100 [==============================] - 21s 206ms/step - loss: 1.3650 - accuracy: 0.6234 - val_loss: 1.9148 - val_accuracy: 0.4986\n",
            "Epoch 71/350\n",
            "100/100 [==============================] - 21s 207ms/step - loss: 1.3656 - accuracy: 0.6153 - val_loss: 1.9944 - val_accuracy: 0.5020\n",
            "Epoch 72/350\n",
            "100/100 [==============================] - 16s 155ms/step - loss: 1.3642 - accuracy: 0.6205 - val_loss: 1.8130 - val_accuracy: 0.5207\n",
            "Epoch 73/350\n",
            "100/100 [==============================] - 16s 162ms/step - loss: 1.3402 - accuracy: 0.6255 - val_loss: 1.8536 - val_accuracy: 0.5130\n",
            "Epoch 74/350\n",
            "100/100 [==============================] - 16s 157ms/step - loss: 1.3531 - accuracy: 0.6184 - val_loss: 1.7205 - val_accuracy: 0.5392\n",
            "Epoch 75/350\n",
            "100/100 [==============================] - 16s 156ms/step - loss: 1.3682 - accuracy: 0.6134 - val_loss: 1.9259 - val_accuracy: 0.4943\n",
            "Epoch 76/350\n",
            "100/100 [==============================] - 16s 157ms/step - loss: 1.3186 - accuracy: 0.6267 - val_loss: 1.7137 - val_accuracy: 0.5368\n",
            "Epoch 77/350\n",
            "100/100 [==============================] - 16s 158ms/step - loss: 1.3024 - accuracy: 0.6380 - val_loss: 1.6056 - val_accuracy: 0.5674\n",
            "Epoch 78/350\n",
            "100/100 [==============================] - 16s 157ms/step - loss: 1.3042 - accuracy: 0.6330 - val_loss: 1.8181 - val_accuracy: 0.5178\n",
            "Epoch 79/350\n",
            "100/100 [==============================] - 20s 205ms/step - loss: 1.2965 - accuracy: 0.6327 - val_loss: 1.6987 - val_accuracy: 0.5404\n",
            "Epoch 80/350\n",
            "100/100 [==============================] - 16s 156ms/step - loss: 1.2407 - accuracy: 0.6527 - val_loss: 1.7508 - val_accuracy: 0.5337\n",
            "Epoch 81/350\n",
            "100/100 [==============================] - 16s 159ms/step - loss: 1.2564 - accuracy: 0.6492 - val_loss: 1.7109 - val_accuracy: 0.5438\n",
            "Epoch 82/350\n",
            "100/100 [==============================] - 16s 156ms/step - loss: 1.2736 - accuracy: 0.6372 - val_loss: 1.8922 - val_accuracy: 0.5102\n",
            "Epoch 83/350\n",
            "100/100 [==============================] - 16s 156ms/step - loss: 1.2300 - accuracy: 0.6461 - val_loss: 1.7429 - val_accuracy: 0.5382\n",
            "Epoch 84/350\n",
            "100/100 [==============================] - 16s 156ms/step - loss: 1.2344 - accuracy: 0.6509 - val_loss: 2.0747 - val_accuracy: 0.4830\n",
            "Epoch 85/350\n",
            "100/100 [==============================] - 16s 158ms/step - loss: 1.2044 - accuracy: 0.6538 - val_loss: 1.6702 - val_accuracy: 0.5576\n",
            "Epoch 86/350\n",
            "100/100 [==============================] - 20s 206ms/step - loss: 1.2013 - accuracy: 0.6614 - val_loss: 1.7813 - val_accuracy: 0.5209\n",
            "Epoch 87/350\n",
            "100/100 [==============================] - 16s 156ms/step - loss: 1.1974 - accuracy: 0.6612 - val_loss: 1.6281 - val_accuracy: 0.5564\n",
            "Epoch 88/350\n",
            "100/100 [==============================] - 21s 208ms/step - loss: 1.2016 - accuracy: 0.6525 - val_loss: 1.5551 - val_accuracy: 0.5749\n",
            "Epoch 89/350\n",
            "100/100 [==============================] - 16s 157ms/step - loss: 1.2090 - accuracy: 0.6525 - val_loss: 1.7742 - val_accuracy: 0.5308\n",
            "Epoch 90/350\n",
            "100/100 [==============================] - 21s 207ms/step - loss: 1.1689 - accuracy: 0.6653 - val_loss: 1.6681 - val_accuracy: 0.5563\n",
            "Epoch 91/350\n",
            "100/100 [==============================] - 16s 156ms/step - loss: 1.1665 - accuracy: 0.6731 - val_loss: 1.7179 - val_accuracy: 0.5442\n",
            "Epoch 92/350\n",
            "100/100 [==============================] - 16s 155ms/step - loss: 1.1515 - accuracy: 0.6689 - val_loss: 1.6940 - val_accuracy: 0.5536\n",
            "Epoch 93/350\n",
            "100/100 [==============================] - 16s 157ms/step - loss: 1.1360 - accuracy: 0.6825 - val_loss: 1.7839 - val_accuracy: 0.5371\n",
            "Epoch 94/350\n",
            "100/100 [==============================] - 21s 206ms/step - loss: 1.1509 - accuracy: 0.6691 - val_loss: 1.6068 - val_accuracy: 0.5736\n",
            "Epoch 95/350\n",
            "100/100 [==============================] - 16s 156ms/step - loss: 1.1392 - accuracy: 0.6786 - val_loss: 1.6315 - val_accuracy: 0.5720\n",
            "Epoch 96/350\n",
            "100/100 [==============================] - 16s 158ms/step - loss: 1.1211 - accuracy: 0.6825 - val_loss: 1.6253 - val_accuracy: 0.5650\n",
            "Epoch 97/350\n",
            "100/100 [==============================] - 16s 158ms/step - loss: 1.1187 - accuracy: 0.6802 - val_loss: 1.6120 - val_accuracy: 0.5756\n",
            "Epoch 98/350\n",
            "100/100 [==============================] - 16s 156ms/step - loss: 1.0962 - accuracy: 0.6800 - val_loss: 1.6839 - val_accuracy: 0.5600\n",
            "Epoch 99/350\n",
            "100/100 [==============================] - 20s 205ms/step - loss: 1.1092 - accuracy: 0.6789 - val_loss: 1.8136 - val_accuracy: 0.5296\n",
            "Epoch 100/350\n",
            "100/100 [==============================] - 16s 156ms/step - loss: 1.0616 - accuracy: 0.6936 - val_loss: 1.6129 - val_accuracy: 0.5780\n",
            "Epoch 101/350\n",
            "100/100 [==============================] - 21s 207ms/step - loss: 1.0661 - accuracy: 0.6913 - val_loss: 1.5833 - val_accuracy: 0.5737\n",
            "Epoch 102/350\n",
            "100/100 [==============================] - 16s 156ms/step - loss: 1.0441 - accuracy: 0.6997 - val_loss: 1.6335 - val_accuracy: 0.5649\n",
            "Epoch 103/350\n",
            "100/100 [==============================] - 16s 163ms/step - loss: 1.0570 - accuracy: 0.6964 - val_loss: 1.5873 - val_accuracy: 0.5748\n",
            "Epoch 104/350\n",
            "100/100 [==============================] - 21s 208ms/step - loss: 1.0468 - accuracy: 0.6991 - val_loss: 1.6698 - val_accuracy: 0.5674\n",
            "Epoch 105/350\n",
            "100/100 [==============================] - 15s 155ms/step - loss: 1.0852 - accuracy: 0.6856 - val_loss: 1.7437 - val_accuracy: 0.5453\n",
            "Epoch 106/350\n",
            "100/100 [==============================] - 21s 206ms/step - loss: 1.0335 - accuracy: 0.7044 - val_loss: 1.7204 - val_accuracy: 0.5525\n",
            "Epoch 107/350\n",
            "100/100 [==============================] - 20s 205ms/step - loss: 1.0203 - accuracy: 0.7103 - val_loss: 1.6660 - val_accuracy: 0.5601\n",
            "Epoch 108/350\n",
            "100/100 [==============================] - 21s 206ms/step - loss: 0.9959 - accuracy: 0.7127 - val_loss: 1.6209 - val_accuracy: 0.5741\n",
            "Epoch 109/350\n",
            "100/100 [==============================] - 21s 208ms/step - loss: 1.0360 - accuracy: 0.7014 - val_loss: 1.5113 - val_accuracy: 0.5930\n",
            "Epoch 110/350\n",
            "100/100 [==============================] - 16s 156ms/step - loss: 1.0092 - accuracy: 0.7064 - val_loss: 1.6374 - val_accuracy: 0.5704\n",
            "Epoch 111/350\n",
            "100/100 [==============================] - 16s 156ms/step - loss: 0.9753 - accuracy: 0.7231 - val_loss: 1.6534 - val_accuracy: 0.5670\n",
            "Epoch 112/350\n",
            "100/100 [==============================] - 21s 207ms/step - loss: 0.9950 - accuracy: 0.7147 - val_loss: 1.6552 - val_accuracy: 0.5633\n",
            "Epoch 113/350\n",
            "100/100 [==============================] - 16s 157ms/step - loss: 0.9861 - accuracy: 0.7156 - val_loss: 1.5971 - val_accuracy: 0.5670\n",
            "Epoch 114/350\n",
            "100/100 [==============================] - 16s 162ms/step - loss: 0.9585 - accuracy: 0.7150 - val_loss: 1.4785 - val_accuracy: 0.6030\n",
            "Epoch 115/350\n",
            "100/100 [==============================] - 16s 158ms/step - loss: 0.9691 - accuracy: 0.7194 - val_loss: 1.5794 - val_accuracy: 0.5761\n",
            "Epoch 116/350\n",
            "100/100 [==============================] - 16s 155ms/step - loss: 0.9577 - accuracy: 0.7308 - val_loss: 1.4705 - val_accuracy: 0.6046\n",
            "Epoch 117/350\n",
            "100/100 [==============================] - 20s 205ms/step - loss: 0.9805 - accuracy: 0.7192 - val_loss: 1.5548 - val_accuracy: 0.5908\n",
            "Epoch 118/350\n",
            "100/100 [==============================] - 16s 157ms/step - loss: 0.9438 - accuracy: 0.7252 - val_loss: 1.6290 - val_accuracy: 0.5662\n",
            "Epoch 119/350\n",
            "100/100 [==============================] - 21s 207ms/step - loss: 0.9188 - accuracy: 0.7319 - val_loss: 1.5237 - val_accuracy: 0.5908\n",
            "Epoch 120/350\n",
            "100/100 [==============================] - 16s 156ms/step - loss: 0.9430 - accuracy: 0.7262 - val_loss: 1.5232 - val_accuracy: 0.5928\n",
            "Epoch 121/350\n",
            "100/100 [==============================] - 16s 156ms/step - loss: 0.9161 - accuracy: 0.7359 - val_loss: 1.5413 - val_accuracy: 0.5920\n",
            "Epoch 122/350\n",
            "100/100 [==============================] - 16s 156ms/step - loss: 0.9180 - accuracy: 0.7344 - val_loss: 1.4820 - val_accuracy: 0.6047\n",
            "Epoch 123/350\n",
            "100/100 [==============================] - 21s 206ms/step - loss: 0.8880 - accuracy: 0.7377 - val_loss: 1.7188 - val_accuracy: 0.5604\n",
            "Epoch 124/350\n",
            "100/100 [==============================] - 20s 205ms/step - loss: 0.8759 - accuracy: 0.7405 - val_loss: 1.5547 - val_accuracy: 0.5897\n",
            "Epoch 125/350\n",
            "100/100 [==============================] - 16s 157ms/step - loss: 0.8855 - accuracy: 0.7412 - val_loss: 1.5952 - val_accuracy: 0.5770\n",
            "Epoch 126/350\n",
            "100/100 [==============================] - 21s 209ms/step - loss: 0.8810 - accuracy: 0.7431 - val_loss: 1.6807 - val_accuracy: 0.5626\n",
            "Epoch 127/350\n",
            "100/100 [==============================] - 21s 205ms/step - loss: 0.9131 - accuracy: 0.7342 - val_loss: 1.5570 - val_accuracy: 0.5885\n",
            "Epoch 128/350\n",
            "100/100 [==============================] - 16s 155ms/step - loss: 0.8690 - accuracy: 0.7461 - val_loss: 1.5511 - val_accuracy: 0.5904\n",
            "Epoch 129/350\n",
            "100/100 [==============================] - 16s 157ms/step - loss: 0.9072 - accuracy: 0.7387 - val_loss: 1.5125 - val_accuracy: 0.5986\n",
            "Epoch 130/350\n",
            "100/100 [==============================] - 16s 158ms/step - loss: 0.8804 - accuracy: 0.7478 - val_loss: 1.5040 - val_accuracy: 0.6031\n",
            "Epoch 131/350\n",
            "100/100 [==============================] - 16s 156ms/step - loss: 0.8570 - accuracy: 0.7473 - val_loss: 1.4646 - val_accuracy: 0.6060\n",
            "Epoch 132/350\n",
            "100/100 [==============================] - 16s 155ms/step - loss: 0.8377 - accuracy: 0.7589 - val_loss: 1.5985 - val_accuracy: 0.5833\n",
            "Epoch 133/350\n",
            "100/100 [==============================] - 16s 156ms/step - loss: 0.8402 - accuracy: 0.7520 - val_loss: 1.5277 - val_accuracy: 0.5926\n",
            "Epoch 134/350\n",
            "100/100 [==============================] - 20s 206ms/step - loss: 0.8395 - accuracy: 0.7548 - val_loss: 1.5754 - val_accuracy: 0.5884\n",
            "Epoch 135/350\n",
            "100/100 [==============================] - 20s 205ms/step - loss: 0.8265 - accuracy: 0.7603 - val_loss: 1.5343 - val_accuracy: 0.6022\n",
            "Epoch 136/350\n",
            "100/100 [==============================] - 21s 207ms/step - loss: 0.8064 - accuracy: 0.7652 - val_loss: 1.7815 - val_accuracy: 0.5608\n",
            "Epoch 137/350\n",
            "100/100 [==============================] - 16s 156ms/step - loss: 0.8458 - accuracy: 0.7533 - val_loss: 1.5619 - val_accuracy: 0.5924\n",
            "Epoch 138/350\n",
            "100/100 [==============================] - 16s 162ms/step - loss: 0.7922 - accuracy: 0.7670 - val_loss: 1.5011 - val_accuracy: 0.6034\n",
            "Epoch 139/350\n",
            "100/100 [==============================] - 16s 157ms/step - loss: 0.8205 - accuracy: 0.7586 - val_loss: 1.6018 - val_accuracy: 0.5847\n",
            "Epoch 140/350\n",
            "100/100 [==============================] - 16s 155ms/step - loss: 0.7972 - accuracy: 0.7663 - val_loss: 1.5413 - val_accuracy: 0.6032\n",
            "Epoch 141/350\n",
            "100/100 [==============================] - 16s 156ms/step - loss: 0.7910 - accuracy: 0.7680 - val_loss: 1.6315 - val_accuracy: 0.5834\n",
            "Epoch 142/350\n",
            "100/100 [==============================] - 21s 206ms/step - loss: 0.7925 - accuracy: 0.7683 - val_loss: 1.4831 - val_accuracy: 0.6097\n",
            "Epoch 143/350\n",
            "100/100 [==============================] - 16s 157ms/step - loss: 0.7967 - accuracy: 0.7644 - val_loss: 1.5080 - val_accuracy: 0.6008\n",
            "Epoch 144/350\n",
            "100/100 [==============================] - 20s 205ms/step - loss: 0.7444 - accuracy: 0.7820 - val_loss: 1.5808 - val_accuracy: 0.5919\n",
            "Epoch 145/350\n",
            "100/100 [==============================] - 16s 156ms/step - loss: 0.7627 - accuracy: 0.7836 - val_loss: 1.5291 - val_accuracy: 0.5990\n",
            "Epoch 146/350\n",
            "100/100 [==============================] - 21s 206ms/step - loss: 0.7627 - accuracy: 0.7764 - val_loss: 1.4793 - val_accuracy: 0.6131\n",
            "Epoch 147/350\n",
            "100/100 [==============================] - 20s 205ms/step - loss: 0.7635 - accuracy: 0.7770 - val_loss: 1.5483 - val_accuracy: 0.6000\n",
            "Epoch 148/350\n",
            "100/100 [==============================] - 16s 160ms/step - loss: 0.7576 - accuracy: 0.7769 - val_loss: 1.4736 - val_accuracy: 0.6121\n",
            "Epoch 149/350\n",
            "100/100 [==============================] - 16s 161ms/step - loss: 0.7451 - accuracy: 0.7809 - val_loss: 1.4136 - val_accuracy: 0.6270\n",
            "Epoch 150/350\n",
            "100/100 [==============================] - 16s 156ms/step - loss: 0.7244 - accuracy: 0.7925 - val_loss: 1.5879 - val_accuracy: 0.5876\n",
            "Epoch 151/350\n",
            "100/100 [==============================] - 16s 156ms/step - loss: 0.7419 - accuracy: 0.7784 - val_loss: 1.5625 - val_accuracy: 0.6015\n",
            "Epoch 152/350\n",
            "100/100 [==============================] - 16s 157ms/step - loss: 0.7162 - accuracy: 0.7853 - val_loss: 1.5951 - val_accuracy: 0.5872\n",
            "Epoch 153/350\n",
            "100/100 [==============================] - 16s 158ms/step - loss: 0.7566 - accuracy: 0.7789 - val_loss: 1.5859 - val_accuracy: 0.5977\n",
            "Epoch 154/350\n",
            "100/100 [==============================] - 16s 156ms/step - loss: 0.7056 - accuracy: 0.7902 - val_loss: 1.5414 - val_accuracy: 0.5960\n",
            "Epoch 155/350\n",
            "100/100 [==============================] - 16s 156ms/step - loss: 0.7212 - accuracy: 0.7869 - val_loss: 1.4666 - val_accuracy: 0.6163\n",
            "Epoch 156/350\n",
            "100/100 [==============================] - 16s 156ms/step - loss: 0.7079 - accuracy: 0.7936 - val_loss: 1.6324 - val_accuracy: 0.5904\n",
            "Epoch 157/350\n",
            "100/100 [==============================] - 16s 158ms/step - loss: 0.6994 - accuracy: 0.7923 - val_loss: 1.7273 - val_accuracy: 0.5712\n",
            "Epoch 158/350\n",
            "100/100 [==============================] - 21s 207ms/step - loss: 0.6991 - accuracy: 0.7862 - val_loss: 1.4759 - val_accuracy: 0.6151\n",
            "Epoch 159/350\n",
            "100/100 [==============================] - 21s 206ms/step - loss: 0.6992 - accuracy: 0.7980 - val_loss: 1.4931 - val_accuracy: 0.6175\n",
            "Epoch 160/350\n",
            "100/100 [==============================] - 20s 205ms/step - loss: 0.6865 - accuracy: 0.7969 - val_loss: 1.5118 - val_accuracy: 0.6150\n",
            "Epoch 161/350\n",
            "100/100 [==============================] - 16s 162ms/step - loss: 0.6845 - accuracy: 0.7945 - val_loss: 1.5801 - val_accuracy: 0.5915\n",
            "Epoch 162/350\n",
            "100/100 [==============================] - 21s 210ms/step - loss: 0.6704 - accuracy: 0.8019 - val_loss: 1.5189 - val_accuracy: 0.6126\n",
            "Epoch 163/350\n",
            "100/100 [==============================] - 16s 156ms/step - loss: 0.6949 - accuracy: 0.7945 - val_loss: 1.5805 - val_accuracy: 0.6030\n",
            "Epoch 164/350\n",
            "100/100 [==============================] - 16s 160ms/step - loss: 0.6710 - accuracy: 0.8014 - val_loss: 1.4748 - val_accuracy: 0.6147\n",
            "Epoch 165/350\n",
            "100/100 [==============================] - 21s 208ms/step - loss: 0.6673 - accuracy: 0.8052 - val_loss: 1.4977 - val_accuracy: 0.6207\n",
            "Epoch 166/350\n",
            "100/100 [==============================] - 16s 156ms/step - loss: 0.6509 - accuracy: 0.8072 - val_loss: 1.5292 - val_accuracy: 0.6075\n",
            "Epoch 167/350\n",
            "100/100 [==============================] - 16s 156ms/step - loss: 0.6671 - accuracy: 0.8005 - val_loss: 1.5538 - val_accuracy: 0.6029\n",
            "Epoch 168/350\n",
            "100/100 [==============================] - 16s 160ms/step - loss: 0.6476 - accuracy: 0.8092 - val_loss: 1.4990 - val_accuracy: 0.6136\n",
            "Epoch 169/350\n",
            "100/100 [==============================] - 21s 206ms/step - loss: 0.6611 - accuracy: 0.8048 - val_loss: 1.5509 - val_accuracy: 0.6085\n",
            "Epoch 170/350\n",
            "100/100 [==============================] - 16s 156ms/step - loss: 0.6413 - accuracy: 0.8117 - val_loss: 1.5111 - val_accuracy: 0.6158\n",
            "Epoch 171/350\n",
            "100/100 [==============================] - 16s 162ms/step - loss: 0.6279 - accuracy: 0.8150 - val_loss: 1.5559 - val_accuracy: 0.5994\n",
            "Epoch 172/350\n",
            "100/100 [==============================] - 16s 162ms/step - loss: 0.6181 - accuracy: 0.8142 - val_loss: 1.5676 - val_accuracy: 0.6028\n",
            "Epoch 173/350\n",
            "100/100 [==============================] - 16s 155ms/step - loss: 0.6279 - accuracy: 0.8158 - val_loss: 1.4397 - val_accuracy: 0.6292\n",
            "Epoch 174/350\n",
            "100/100 [==============================] - 16s 155ms/step - loss: 0.6169 - accuracy: 0.8133 - val_loss: 1.4798 - val_accuracy: 0.6150\n",
            "Epoch 175/350\n",
            "100/100 [==============================] - 21s 207ms/step - loss: 0.6181 - accuracy: 0.8195 - val_loss: 1.5078 - val_accuracy: 0.6167\n",
            "Epoch 176/350\n",
            "100/100 [==============================] - 16s 160ms/step - loss: 0.6247 - accuracy: 0.8119 - val_loss: 1.4422 - val_accuracy: 0.6303\n",
            "Epoch 177/350\n",
            "100/100 [==============================] - 21s 206ms/step - loss: 0.6201 - accuracy: 0.8164 - val_loss: 1.5671 - val_accuracy: 0.6158\n",
            "Epoch 178/350\n",
            "100/100 [==============================] - 16s 156ms/step - loss: 0.5977 - accuracy: 0.8230 - val_loss: 1.4423 - val_accuracy: 0.6232\n",
            "Epoch 179/350\n",
            "100/100 [==============================] - 16s 158ms/step - loss: 0.5814 - accuracy: 0.8322 - val_loss: 1.5767 - val_accuracy: 0.6079\n",
            "Epoch 180/350\n",
            "100/100 [==============================] - 16s 157ms/step - loss: 0.5912 - accuracy: 0.8192 - val_loss: 1.4577 - val_accuracy: 0.6289\n",
            "Epoch 181/350\n",
            "100/100 [==============================] - 16s 157ms/step - loss: 0.5773 - accuracy: 0.8230 - val_loss: 1.5830 - val_accuracy: 0.6008\n",
            "Epoch 182/350\n",
            "100/100 [==============================] - 20s 206ms/step - loss: 0.5872 - accuracy: 0.8252 - val_loss: 1.5219 - val_accuracy: 0.6199\n",
            "Epoch 183/350\n",
            "100/100 [==============================] - 21s 205ms/step - loss: 0.5640 - accuracy: 0.8264 - val_loss: 1.5009 - val_accuracy: 0.6182\n",
            "Epoch 184/350\n",
            "100/100 [==============================] - 21s 208ms/step - loss: 0.5443 - accuracy: 0.8359 - val_loss: 1.4455 - val_accuracy: 0.6339\n",
            "Epoch 185/350\n",
            "100/100 [==============================] - 16s 160ms/step - loss: 0.5639 - accuracy: 0.8317 - val_loss: 1.4461 - val_accuracy: 0.6350\n",
            "Epoch 186/350\n",
            "100/100 [==============================] - 20s 206ms/step - loss: 0.5700 - accuracy: 0.8261 - val_loss: 1.4637 - val_accuracy: 0.6265\n",
            "Epoch 187/350\n",
            "100/100 [==============================] - 16s 156ms/step - loss: 0.5597 - accuracy: 0.8345 - val_loss: 1.4610 - val_accuracy: 0.6291\n",
            "Epoch 188/350\n",
            "100/100 [==============================] - 16s 162ms/step - loss: 0.5247 - accuracy: 0.8373 - val_loss: 1.5930 - val_accuracy: 0.6047\n",
            "Epoch 189/350\n",
            "100/100 [==============================] - 21s 210ms/step - loss: 0.5590 - accuracy: 0.8252 - val_loss: 1.4753 - val_accuracy: 0.6221\n",
            "Epoch 190/350\n",
            "100/100 [==============================] - 16s 155ms/step - loss: 0.5536 - accuracy: 0.8331 - val_loss: 1.4538 - val_accuracy: 0.6347\n",
            "Epoch 191/350\n",
            "100/100 [==============================] - 16s 156ms/step - loss: 0.5624 - accuracy: 0.8305 - val_loss: 1.5270 - val_accuracy: 0.6185\n",
            "Epoch 192/350\n",
            "100/100 [==============================] - 16s 161ms/step - loss: 0.5438 - accuracy: 0.8395 - val_loss: 1.4988 - val_accuracy: 0.6240\n",
            "Epoch 193/350\n",
            "100/100 [==============================] - 16s 157ms/step - loss: 0.5383 - accuracy: 0.8405 - val_loss: 1.5431 - val_accuracy: 0.6224\n",
            "Epoch 194/350\n",
            "100/100 [==============================] - 16s 156ms/step - loss: 0.5238 - accuracy: 0.8452 - val_loss: 1.4453 - val_accuracy: 0.6337\n",
            "Epoch 195/350\n",
            "100/100 [==============================] - 16s 158ms/step - loss: 0.5244 - accuracy: 0.8461 - val_loss: 1.4661 - val_accuracy: 0.6376\n",
            "Epoch 196/350\n",
            "100/100 [==============================] - 21s 206ms/step - loss: 0.5412 - accuracy: 0.8366 - val_loss: 1.6012 - val_accuracy: 0.6131\n",
            "Epoch 197/350\n",
            "100/100 [==============================] - 21s 206ms/step - loss: 0.5153 - accuracy: 0.8498 - val_loss: 1.4548 - val_accuracy: 0.6302\n",
            "Epoch 198/350\n",
            "100/100 [==============================] - 16s 163ms/step - loss: 0.5285 - accuracy: 0.8403 - val_loss: 1.6852 - val_accuracy: 0.5882\n",
            "Epoch 199/350\n",
            "100/100 [==============================] - 21s 206ms/step - loss: 0.5259 - accuracy: 0.8420 - val_loss: 1.4574 - val_accuracy: 0.6288\n",
            "Epoch 200/350\n",
            "100/100 [==============================] - 16s 156ms/step - loss: 0.4972 - accuracy: 0.8519 - val_loss: 1.5785 - val_accuracy: 0.6196\n",
            "Epoch 201/350\n",
            "100/100 [==============================] - 16s 163ms/step - loss: 0.5224 - accuracy: 0.8462 - val_loss: 1.5757 - val_accuracy: 0.6160\n",
            "Epoch 202/350\n",
            "100/100 [==============================] - 16s 161ms/step - loss: 0.5154 - accuracy: 0.8398 - val_loss: 1.4754 - val_accuracy: 0.6278\n",
            "Epoch 203/350\n",
            "100/100 [==============================] - 16s 155ms/step - loss: 0.5016 - accuracy: 0.8434 - val_loss: 1.5104 - val_accuracy: 0.6268\n",
            "Epoch 204/350\n",
            "100/100 [==============================] - 16s 156ms/step - loss: 0.4951 - accuracy: 0.8492 - val_loss: 1.4893 - val_accuracy: 0.6302\n",
            "Epoch 205/350\n",
            "100/100 [==============================] - 16s 157ms/step - loss: 0.4890 - accuracy: 0.8544 - val_loss: 1.5993 - val_accuracy: 0.6071\n",
            "Epoch 206/350\n",
            "100/100 [==============================] - 16s 159ms/step - loss: 0.5039 - accuracy: 0.8530 - val_loss: 1.8363 - val_accuracy: 0.5668\n",
            "Epoch 207/350\n",
            "100/100 [==============================] - 16s 156ms/step - loss: 0.4837 - accuracy: 0.8572 - val_loss: 1.5660 - val_accuracy: 0.6241\n",
            "Epoch 208/350\n",
            "100/100 [==============================] - 21s 206ms/step - loss: 0.4759 - accuracy: 0.8553 - val_loss: 1.4791 - val_accuracy: 0.6428\n",
            "Epoch 209/350\n",
            "100/100 [==============================] - 16s 158ms/step - loss: 0.4817 - accuracy: 0.8566 - val_loss: 1.4702 - val_accuracy: 0.6369\n",
            "Epoch 210/350\n",
            "100/100 [==============================] - 16s 163ms/step - loss: 0.4863 - accuracy: 0.8489 - val_loss: 1.5223 - val_accuracy: 0.6286\n",
            "Epoch 211/350\n",
            "100/100 [==============================] - 21s 207ms/step - loss: 0.4961 - accuracy: 0.8516 - val_loss: 1.6057 - val_accuracy: 0.6194\n",
            "Epoch 212/350\n",
            "100/100 [==============================] - 20s 205ms/step - loss: 0.4718 - accuracy: 0.8566 - val_loss: 1.5353 - val_accuracy: 0.6262\n",
            "Epoch 213/350\n",
            "100/100 [==============================] - 21s 206ms/step - loss: 0.4689 - accuracy: 0.8628 - val_loss: 1.5303 - val_accuracy: 0.6295\n",
            "Epoch 214/350\n",
            "100/100 [==============================] - 16s 164ms/step - loss: 0.4701 - accuracy: 0.8567 - val_loss: 1.5550 - val_accuracy: 0.6224\n",
            "Epoch 215/350\n",
            "100/100 [==============================] - 16s 157ms/step - loss: 0.4585 - accuracy: 0.8661 - val_loss: 1.5235 - val_accuracy: 0.6350\n",
            "Epoch 216/350\n",
            "100/100 [==============================] - 16s 155ms/step - loss: 0.4751 - accuracy: 0.8542 - val_loss: 1.6030 - val_accuracy: 0.6142\n",
            "Epoch 217/350\n",
            "100/100 [==============================] - 16s 157ms/step - loss: 0.4426 - accuracy: 0.8656 - val_loss: 1.6743 - val_accuracy: 0.5999\n",
            "Epoch 218/350\n",
            "100/100 [==============================] - 21s 207ms/step - loss: 0.4587 - accuracy: 0.8589 - val_loss: 1.4929 - val_accuracy: 0.6283\n",
            "Epoch 219/350\n",
            "100/100 [==============================] - 16s 156ms/step - loss: 0.4585 - accuracy: 0.8634 - val_loss: 1.5374 - val_accuracy: 0.6163\n",
            "Epoch 220/350\n",
            "100/100 [==============================] - 16s 156ms/step - loss: 0.4386 - accuracy: 0.8664 - val_loss: 1.5182 - val_accuracy: 0.6208\n",
            "Epoch 221/350\n",
            "100/100 [==============================] - 21s 207ms/step - loss: 0.4419 - accuracy: 0.8680 - val_loss: 1.5018 - val_accuracy: 0.6382\n",
            "Epoch 222/350\n",
            "100/100 [==============================] - 16s 158ms/step - loss: 0.4449 - accuracy: 0.8645 - val_loss: 1.5901 - val_accuracy: 0.6092\n",
            "Epoch 223/350\n",
            "100/100 [==============================] - 16s 158ms/step - loss: 0.4477 - accuracy: 0.8606 - val_loss: 1.6003 - val_accuracy: 0.6094\n",
            "Epoch 224/350\n",
            "100/100 [==============================] - 16s 156ms/step - loss: 0.4322 - accuracy: 0.8662 - val_loss: 1.5906 - val_accuracy: 0.6220\n",
            "Epoch 225/350\n",
            "100/100 [==============================] - 16s 157ms/step - loss: 0.4432 - accuracy: 0.8644 - val_loss: 1.5741 - val_accuracy: 0.6216\n",
            "Epoch 226/350\n",
            "100/100 [==============================] - 16s 159ms/step - loss: 0.4323 - accuracy: 0.8683 - val_loss: 1.6572 - val_accuracy: 0.6039\n",
            "Epoch 227/350\n",
            "100/100 [==============================] - 21s 207ms/step - loss: 0.4249 - accuracy: 0.8744 - val_loss: 1.4932 - val_accuracy: 0.6350\n",
            "Epoch 228/350\n",
            "100/100 [==============================] - 16s 156ms/step - loss: 0.4137 - accuracy: 0.8750 - val_loss: 1.6377 - val_accuracy: 0.6153\n",
            "Epoch 229/350\n",
            "100/100 [==============================] - 16s 164ms/step - loss: 0.4192 - accuracy: 0.8716 - val_loss: 1.5982 - val_accuracy: 0.6133\n",
            "Epoch 230/350\n",
            "100/100 [==============================] - 16s 161ms/step - loss: 0.4336 - accuracy: 0.8695 - val_loss: 1.4919 - val_accuracy: 0.6386\n",
            "Epoch 231/350\n",
            "100/100 [==============================] - 20s 206ms/step - loss: 0.4334 - accuracy: 0.8664 - val_loss: 1.5536 - val_accuracy: 0.6268\n",
            "Epoch 232/350\n",
            "100/100 [==============================] - 20s 205ms/step - loss: 0.4126 - accuracy: 0.8773 - val_loss: 1.4646 - val_accuracy: 0.6423\n",
            "Epoch 233/350\n",
            "100/100 [==============================] - 16s 162ms/step - loss: 0.4089 - accuracy: 0.8775 - val_loss: 1.5200 - val_accuracy: 0.6344\n",
            "Epoch 234/350\n",
            "100/100 [==============================] - 16s 162ms/step - loss: 0.4094 - accuracy: 0.8705 - val_loss: 1.4977 - val_accuracy: 0.6362\n",
            "Epoch 235/350\n",
            "100/100 [==============================] - 16s 156ms/step - loss: 0.4076 - accuracy: 0.8741 - val_loss: 1.4919 - val_accuracy: 0.6332\n",
            "Epoch 236/350\n",
            "100/100 [==============================] - 16s 155ms/step - loss: 0.4078 - accuracy: 0.8717 - val_loss: 1.6163 - val_accuracy: 0.6201\n",
            "Epoch 237/350\n",
            "100/100 [==============================] - 21s 206ms/step - loss: 0.4200 - accuracy: 0.8747 - val_loss: 1.5047 - val_accuracy: 0.6349\n",
            "Epoch 238/350\n",
            "100/100 [==============================] - 16s 157ms/step - loss: 0.3922 - accuracy: 0.8806 - val_loss: 1.5767 - val_accuracy: 0.6285\n",
            "Epoch 239/350\n",
            "100/100 [==============================] - 16s 164ms/step - loss: 0.3959 - accuracy: 0.8806 - val_loss: 1.6478 - val_accuracy: 0.6035\n",
            "Epoch 240/350\n",
            "100/100 [==============================] - 16s 158ms/step - loss: 0.3750 - accuracy: 0.8875 - val_loss: 1.5547 - val_accuracy: 0.6198\n",
            "Epoch 241/350\n",
            "100/100 [==============================] - 20s 206ms/step - loss: 0.3907 - accuracy: 0.8822 - val_loss: 1.5691 - val_accuracy: 0.6250\n",
            "Epoch 242/350\n",
            "100/100 [==============================] - 16s 157ms/step - loss: 0.3900 - accuracy: 0.8819 - val_loss: 1.5378 - val_accuracy: 0.6388\n",
            "Epoch 243/350\n",
            "100/100 [==============================] - 16s 159ms/step - loss: 0.3966 - accuracy: 0.8813 - val_loss: 1.6838 - val_accuracy: 0.6090\n",
            "Epoch 244/350\n",
            "100/100 [==============================] - 21s 206ms/step - loss: 0.3852 - accuracy: 0.8844 - val_loss: 1.5500 - val_accuracy: 0.6264\n",
            "Epoch 245/350\n",
            "100/100 [==============================] - 16s 157ms/step - loss: 0.3997 - accuracy: 0.8797 - val_loss: 1.5015 - val_accuracy: 0.6432\n",
            "Epoch 246/350\n",
            "100/100 [==============================] - 16s 163ms/step - loss: 0.3886 - accuracy: 0.8853 - val_loss: 1.5271 - val_accuracy: 0.6362\n",
            "Epoch 247/350\n",
            "100/100 [==============================] - 16s 159ms/step - loss: 0.3724 - accuracy: 0.8853 - val_loss: 1.6490 - val_accuracy: 0.6249\n",
            "Epoch 248/350\n",
            "100/100 [==============================] - 16s 156ms/step - loss: 0.3773 - accuracy: 0.8863 - val_loss: 1.5260 - val_accuracy: 0.6323\n",
            "Epoch 249/350\n",
            "100/100 [==============================] - 20s 205ms/step - loss: 0.3672 - accuracy: 0.8875 - val_loss: 1.4816 - val_accuracy: 0.6394\n",
            "Epoch 250/350\n",
            "100/100 [==============================] - 16s 157ms/step - loss: 0.3570 - accuracy: 0.8898 - val_loss: 1.4978 - val_accuracy: 0.6385\n",
            "Epoch 251/350\n",
            "100/100 [==============================] - 16s 160ms/step - loss: 0.3785 - accuracy: 0.8859 - val_loss: 1.4119 - val_accuracy: 0.6563\n",
            "Epoch 252/350\n",
            "100/100 [==============================] - 16s 159ms/step - loss: 0.3570 - accuracy: 0.8913 - val_loss: 1.5447 - val_accuracy: 0.6332\n",
            "Epoch 253/350\n",
            "100/100 [==============================] - 16s 156ms/step - loss: 0.3736 - accuracy: 0.8842 - val_loss: 1.5308 - val_accuracy: 0.6317\n",
            "Epoch 254/350\n",
            "100/100 [==============================] - 16s 159ms/step - loss: 0.3676 - accuracy: 0.8855 - val_loss: 1.4267 - val_accuracy: 0.6522\n",
            "Epoch 255/350\n",
            "100/100 [==============================] - 16s 157ms/step - loss: 0.3505 - accuracy: 0.8911 - val_loss: 1.5233 - val_accuracy: 0.6427\n",
            "Epoch 256/350\n",
            "100/100 [==============================] - 16s 156ms/step - loss: 0.3619 - accuracy: 0.8866 - val_loss: 1.5445 - val_accuracy: 0.6391\n",
            "Epoch 257/350\n",
            "100/100 [==============================] - 16s 158ms/step - loss: 0.3535 - accuracy: 0.8939 - val_loss: 1.5469 - val_accuracy: 0.6359\n",
            "Epoch 258/350\n",
            "100/100 [==============================] - 16s 160ms/step - loss: 0.3506 - accuracy: 0.8898 - val_loss: 1.4993 - val_accuracy: 0.6443\n",
            "Epoch 259/350\n",
            "100/100 [==============================] - 21s 206ms/step - loss: 0.3497 - accuracy: 0.8939 - val_loss: 1.5079 - val_accuracy: 0.6394\n",
            "Epoch 260/350\n",
            "100/100 [==============================] - 16s 157ms/step - loss: 0.3577 - accuracy: 0.8919 - val_loss: 1.6101 - val_accuracy: 0.6234\n",
            "Epoch 261/350\n",
            "100/100 [==============================] - 16s 163ms/step - loss: 0.3503 - accuracy: 0.8930 - val_loss: 1.5719 - val_accuracy: 0.6323\n",
            "Epoch 262/350\n",
            "100/100 [==============================] - 21s 209ms/step - loss: 0.3483 - accuracy: 0.8906 - val_loss: 1.5356 - val_accuracy: 0.6380\n",
            "Epoch 263/350\n",
            "100/100 [==============================] - 20s 205ms/step - loss: 0.3516 - accuracy: 0.8947 - val_loss: 1.6541 - val_accuracy: 0.6256\n",
            "Epoch 264/350\n",
            "100/100 [==============================] - 16s 162ms/step - loss: 0.3252 - accuracy: 0.9025 - val_loss: 1.6076 - val_accuracy: 0.6216\n",
            "Epoch 265/350\n",
            "100/100 [==============================] - 21s 209ms/step - loss: 0.3439 - accuracy: 0.8963 - val_loss: 1.4806 - val_accuracy: 0.6468\n",
            "Epoch 266/350\n",
            "100/100 [==============================] - 16s 155ms/step - loss: 0.3271 - accuracy: 0.8997 - val_loss: 1.5279 - val_accuracy: 0.6395\n",
            "Epoch 267/350\n",
            "100/100 [==============================] - 16s 157ms/step - loss: 0.3260 - accuracy: 0.8984 - val_loss: 1.5084 - val_accuracy: 0.6473\n",
            "Epoch 268/350\n",
            "100/100 [==============================] - 21s 209ms/step - loss: 0.3322 - accuracy: 0.8963 - val_loss: 1.4792 - val_accuracy: 0.6543\n",
            "Epoch 269/350\n",
            "100/100 [==============================] - 16s 157ms/step - loss: 0.3117 - accuracy: 0.9052 - val_loss: 1.5946 - val_accuracy: 0.6277\n",
            "Epoch 270/350\n",
            "100/100 [==============================] - 16s 156ms/step - loss: 0.3393 - accuracy: 0.8963 - val_loss: 1.5432 - val_accuracy: 0.6312\n",
            "Epoch 271/350\n",
            "100/100 [==============================] - 16s 161ms/step - loss: 0.3165 - accuracy: 0.9050 - val_loss: 1.6026 - val_accuracy: 0.6284\n",
            "Epoch 272/350\n",
            "100/100 [==============================] - 16s 156ms/step - loss: 0.3249 - accuracy: 0.8998 - val_loss: 1.5530 - val_accuracy: 0.6392\n",
            "Epoch 273/350\n",
            "100/100 [==============================] - 16s 157ms/step - loss: 0.3241 - accuracy: 0.9000 - val_loss: 1.5431 - val_accuracy: 0.6366\n",
            "Epoch 274/350\n",
            "100/100 [==============================] - 21s 207ms/step - loss: 0.3109 - accuracy: 0.9087 - val_loss: 1.5536 - val_accuracy: 0.6450\n",
            "Epoch 275/350\n",
            "100/100 [==============================] - 16s 157ms/step - loss: 0.3193 - accuracy: 0.9017 - val_loss: 1.6548 - val_accuracy: 0.6230\n",
            "Epoch 276/350\n",
            "100/100 [==============================] - 21s 209ms/step - loss: 0.3178 - accuracy: 0.9027 - val_loss: 1.5294 - val_accuracy: 0.6444\n",
            "Epoch 277/350\n",
            "100/100 [==============================] - 16s 157ms/step - loss: 0.3217 - accuracy: 0.9039 - val_loss: 1.6188 - val_accuracy: 0.6371\n",
            "Epoch 278/350\n",
            "100/100 [==============================] - 16s 164ms/step - loss: 0.3112 - accuracy: 0.9072 - val_loss: 1.6085 - val_accuracy: 0.6384\n",
            "Epoch 279/350\n",
            "100/100 [==============================] - 16s 161ms/step - loss: 0.3012 - accuracy: 0.9097 - val_loss: 1.6304 - val_accuracy: 0.6304\n",
            "Epoch 280/350\n",
            "100/100 [==============================] - 21s 206ms/step - loss: 0.2959 - accuracy: 0.9106 - val_loss: 1.5539 - val_accuracy: 0.6440\n",
            "Epoch 281/350\n",
            "100/100 [==============================] - 16s 158ms/step - loss: 0.3104 - accuracy: 0.9098 - val_loss: 1.6197 - val_accuracy: 0.6249\n",
            "Epoch 282/350\n",
            "100/100 [==============================] - 16s 163ms/step - loss: 0.2988 - accuracy: 0.9055 - val_loss: 1.5700 - val_accuracy: 0.6338\n",
            "Epoch 283/350\n",
            "100/100 [==============================] - 16s 158ms/step - loss: 0.3009 - accuracy: 0.9058 - val_loss: 1.5414 - val_accuracy: 0.6400\n",
            "Epoch 284/350\n",
            "100/100 [==============================] - 16s 156ms/step - loss: 0.2955 - accuracy: 0.9125 - val_loss: 1.5985 - val_accuracy: 0.6345\n",
            "Epoch 285/350\n",
            "100/100 [==============================] - 16s 156ms/step - loss: 0.3121 - accuracy: 0.9050 - val_loss: 1.5840 - val_accuracy: 0.6378\n",
            "Epoch 286/350\n",
            "100/100 [==============================] - 16s 161ms/step - loss: 0.2810 - accuracy: 0.9148 - val_loss: 1.5708 - val_accuracy: 0.6419\n",
            "Epoch 287/350\n",
            "100/100 [==============================] - 16s 160ms/step - loss: 0.2988 - accuracy: 0.9089 - val_loss: 1.4950 - val_accuracy: 0.6481\n",
            "Epoch 288/350\n",
            "100/100 [==============================] - 16s 156ms/step - loss: 0.2976 - accuracy: 0.9069 - val_loss: 1.5665 - val_accuracy: 0.6375\n",
            "Epoch 289/350\n",
            "100/100 [==============================] - 16s 157ms/step - loss: 0.2868 - accuracy: 0.9123 - val_loss: 1.6380 - val_accuracy: 0.6264\n",
            "Epoch 290/350\n",
            "100/100 [==============================] - 16s 158ms/step - loss: 0.2803 - accuracy: 0.9172 - val_loss: 1.6402 - val_accuracy: 0.6388\n",
            "Epoch 291/350\n",
            "100/100 [==============================] - 16s 157ms/step - loss: 0.2867 - accuracy: 0.9131 - val_loss: 1.5169 - val_accuracy: 0.6517\n",
            "Epoch 292/350\n",
            "100/100 [==============================] - 16s 156ms/step - loss: 0.2881 - accuracy: 0.9084 - val_loss: 1.6821 - val_accuracy: 0.6244\n",
            "Epoch 293/350\n",
            "100/100 [==============================] - 16s 158ms/step - loss: 0.2818 - accuracy: 0.9141 - val_loss: 1.5699 - val_accuracy: 0.6416\n",
            "Epoch 294/350\n",
            "100/100 [==============================] - 16s 157ms/step - loss: 0.2833 - accuracy: 0.9145 - val_loss: 1.6532 - val_accuracy: 0.6299\n",
            "Epoch 295/350\n",
            "100/100 [==============================] - 21s 206ms/step - loss: 0.2821 - accuracy: 0.9170 - val_loss: 1.6371 - val_accuracy: 0.6290\n",
            "Epoch 296/350\n",
            "100/100 [==============================] - 21s 207ms/step - loss: 0.2847 - accuracy: 0.9136 - val_loss: 1.5904 - val_accuracy: 0.6348\n",
            "Epoch 297/350\n",
            "100/100 [==============================] - 16s 158ms/step - loss: 0.2840 - accuracy: 0.9128 - val_loss: 1.6749 - val_accuracy: 0.6271\n",
            "Epoch 298/350\n",
            "100/100 [==============================] - 21s 207ms/step - loss: 0.2691 - accuracy: 0.9162 - val_loss: 1.5726 - val_accuracy: 0.6401\n",
            "Epoch 299/350\n",
            "100/100 [==============================] - 16s 157ms/step - loss: 0.2730 - accuracy: 0.9137 - val_loss: 1.5479 - val_accuracy: 0.6450\n",
            "Epoch 300/350\n",
            "100/100 [==============================] - 16s 164ms/step - loss: 0.2600 - accuracy: 0.9169 - val_loss: 1.6318 - val_accuracy: 0.6328\n",
            "Epoch 301/350\n",
            "100/100 [==============================] - 16s 162ms/step - loss: 0.2831 - accuracy: 0.9144 - val_loss: 1.5047 - val_accuracy: 0.6500\n",
            "Epoch 302/350\n",
            "100/100 [==============================] - 16s 156ms/step - loss: 0.2689 - accuracy: 0.9211 - val_loss: 1.5021 - val_accuracy: 0.6598\n",
            "Epoch 303/350\n",
            "100/100 [==============================] - 16s 156ms/step - loss: 0.2577 - accuracy: 0.9217 - val_loss: 1.6216 - val_accuracy: 0.6369\n",
            "Epoch 304/350\n",
            "100/100 [==============================] - 20s 206ms/step - loss: 0.2741 - accuracy: 0.9158 - val_loss: 1.5695 - val_accuracy: 0.6471\n",
            "Epoch 305/350\n",
            "100/100 [==============================] - 16s 159ms/step - loss: 0.2716 - accuracy: 0.9150 - val_loss: 1.7001 - val_accuracy: 0.6240\n",
            "Epoch 306/350\n",
            "100/100 [==============================] - 17s 166ms/step - loss: 0.2597 - accuracy: 0.9184 - val_loss: 1.5335 - val_accuracy: 0.6462\n",
            "Epoch 307/350\n",
            "100/100 [==============================] - 16s 159ms/step - loss: 0.2720 - accuracy: 0.9164 - val_loss: 1.5546 - val_accuracy: 0.6449\n",
            "Epoch 308/350\n",
            "100/100 [==============================] - 20s 205ms/step - loss: 0.2620 - accuracy: 0.9225 - val_loss: 1.6050 - val_accuracy: 0.6342\n",
            "Epoch 309/350\n",
            "100/100 [==============================] - 16s 158ms/step - loss: 0.2626 - accuracy: 0.9197 - val_loss: 1.6112 - val_accuracy: 0.6411\n",
            "Epoch 310/350\n",
            "100/100 [==============================] - 21s 208ms/step - loss: 0.2645 - accuracy: 0.9180 - val_loss: 1.6009 - val_accuracy: 0.6384\n",
            "Epoch 311/350\n",
            "100/100 [==============================] - 16s 157ms/step - loss: 0.2624 - accuracy: 0.9189 - val_loss: 1.6701 - val_accuracy: 0.6410\n",
            "Epoch 312/350\n",
            "100/100 [==============================] - 16s 157ms/step - loss: 0.2454 - accuracy: 0.9227 - val_loss: 1.5704 - val_accuracy: 0.6508\n",
            "Epoch 313/350\n",
            "100/100 [==============================] - 16s 156ms/step - loss: 0.2459 - accuracy: 0.9184 - val_loss: 1.6482 - val_accuracy: 0.6224\n",
            "Epoch 314/350\n",
            "100/100 [==============================] - 21s 208ms/step - loss: 0.2645 - accuracy: 0.9170 - val_loss: 1.5594 - val_accuracy: 0.6523\n",
            "Epoch 315/350\n",
            "100/100 [==============================] - 16s 156ms/step - loss: 0.2454 - accuracy: 0.9212 - val_loss: 1.7200 - val_accuracy: 0.6231\n",
            "Epoch 316/350\n",
            "100/100 [==============================] - 16s 161ms/step - loss: 0.2509 - accuracy: 0.9234 - val_loss: 1.5934 - val_accuracy: 0.6435\n",
            "Epoch 317/350\n",
            "100/100 [==============================] - 16s 160ms/step - loss: 0.2632 - accuracy: 0.9167 - val_loss: 1.5795 - val_accuracy: 0.6495\n",
            "Epoch 318/350\n",
            "100/100 [==============================] - 21s 206ms/step - loss: 0.2374 - accuracy: 0.9269 - val_loss: 1.5861 - val_accuracy: 0.6411\n",
            "Epoch 319/350\n",
            "100/100 [==============================] - 21s 206ms/step - loss: 0.2549 - accuracy: 0.9237 - val_loss: 1.5978 - val_accuracy: 0.6441\n",
            "Epoch 320/350\n",
            "100/100 [==============================] - 16s 161ms/step - loss: 0.2476 - accuracy: 0.9241 - val_loss: 1.6884 - val_accuracy: 0.6215\n",
            "Epoch 321/350\n",
            "100/100 [==============================] - 21s 211ms/step - loss: 0.2569 - accuracy: 0.9216 - val_loss: 1.6652 - val_accuracy: 0.6231\n",
            "Epoch 322/350\n",
            "100/100 [==============================] - 16s 156ms/step - loss: 0.2464 - accuracy: 0.9277 - val_loss: 1.6084 - val_accuracy: 0.6453\n",
            "Epoch 323/350\n",
            "100/100 [==============================] - 16s 156ms/step - loss: 0.2505 - accuracy: 0.9230 - val_loss: 1.5623 - val_accuracy: 0.6434\n",
            "Epoch 324/350\n",
            "100/100 [==============================] - 16s 160ms/step - loss: 0.2499 - accuracy: 0.9248 - val_loss: 1.6897 - val_accuracy: 0.6281\n",
            "Epoch 325/350\n",
            "100/100 [==============================] - 16s 159ms/step - loss: 0.2402 - accuracy: 0.9306 - val_loss: 1.6240 - val_accuracy: 0.6457\n",
            "Epoch 326/350\n",
            "100/100 [==============================] - 16s 158ms/step - loss: 0.2383 - accuracy: 0.9298 - val_loss: 1.6900 - val_accuracy: 0.6298\n",
            "Epoch 327/350\n",
            "100/100 [==============================] - 16s 156ms/step - loss: 0.2350 - accuracy: 0.9261 - val_loss: 1.5419 - val_accuracy: 0.6532\n",
            "Epoch 328/350\n",
            "100/100 [==============================] - 16s 160ms/step - loss: 0.2357 - accuracy: 0.9302 - val_loss: 1.5681 - val_accuracy: 0.6508\n",
            "Epoch 329/350\n",
            "100/100 [==============================] - 16s 159ms/step - loss: 0.2632 - accuracy: 0.9192 - val_loss: 1.5562 - val_accuracy: 0.6599\n",
            "Epoch 330/350\n",
            "100/100 [==============================] - 21s 206ms/step - loss: 0.2350 - accuracy: 0.9259 - val_loss: 1.5304 - val_accuracy: 0.6595\n",
            "Epoch 331/350\n",
            "100/100 [==============================] - 16s 158ms/step - loss: 0.2348 - accuracy: 0.9284 - val_loss: 1.5607 - val_accuracy: 0.6480\n",
            "Epoch 332/350\n",
            "100/100 [==============================] - 16s 159ms/step - loss: 0.2308 - accuracy: 0.9298 - val_loss: 1.6000 - val_accuracy: 0.6512\n",
            "Epoch 333/350\n",
            "100/100 [==============================] - 16s 157ms/step - loss: 0.2296 - accuracy: 0.9308 - val_loss: 1.5265 - val_accuracy: 0.6572\n",
            "Epoch 334/350\n",
            "100/100 [==============================] - 21s 206ms/step - loss: 0.2318 - accuracy: 0.9302 - val_loss: 1.5919 - val_accuracy: 0.6447\n",
            "Epoch 335/350\n",
            "100/100 [==============================] - 16s 157ms/step - loss: 0.2232 - accuracy: 0.9302 - val_loss: 1.7901 - val_accuracy: 0.6134\n",
            "Epoch 336/350\n",
            "100/100 [==============================] - 16s 164ms/step - loss: 0.2256 - accuracy: 0.9325 - val_loss: 1.6886 - val_accuracy: 0.6450\n",
            "Epoch 337/350\n",
            "100/100 [==============================] - 21s 208ms/step - loss: 0.2216 - accuracy: 0.9309 - val_loss: 1.5884 - val_accuracy: 0.6403\n",
            "Epoch 338/350\n",
            "100/100 [==============================] - 21s 206ms/step - loss: 0.2325 - accuracy: 0.9262 - val_loss: 1.5751 - val_accuracy: 0.6588\n",
            "Epoch 339/350\n",
            "100/100 [==============================] - 21s 206ms/step - loss: 0.2263 - accuracy: 0.9319 - val_loss: 1.6708 - val_accuracy: 0.6365\n",
            "Epoch 340/350\n",
            "100/100 [==============================] - 16s 160ms/step - loss: 0.2128 - accuracy: 0.9355 - val_loss: 1.5955 - val_accuracy: 0.6555\n",
            "Epoch 341/350\n",
            "100/100 [==============================] - 16s 161ms/step - loss: 0.2311 - accuracy: 0.9283 - val_loss: 1.5700 - val_accuracy: 0.6569\n",
            "Epoch 342/350\n",
            "100/100 [==============================] - 21s 206ms/step - loss: 0.2328 - accuracy: 0.9289 - val_loss: 1.5497 - val_accuracy: 0.6644\n",
            "Epoch 343/350\n",
            "100/100 [==============================] - 16s 157ms/step - loss: 0.2098 - accuracy: 0.9388 - val_loss: 1.5559 - val_accuracy: 0.6648\n",
            "Epoch 344/350\n",
            "100/100 [==============================] - 21s 209ms/step - loss: 0.2183 - accuracy: 0.9344 - val_loss: 1.6431 - val_accuracy: 0.6487\n",
            "Epoch 345/350\n",
            "100/100 [==============================] - 16s 157ms/step - loss: 0.2189 - accuracy: 0.9311 - val_loss: 1.5931 - val_accuracy: 0.6559\n",
            "Epoch 346/350\n",
            "100/100 [==============================] - 16s 162ms/step - loss: 0.2140 - accuracy: 0.9323 - val_loss: 1.5503 - val_accuracy: 0.6613\n",
            "Epoch 347/350\n",
            "100/100 [==============================] - 16s 163ms/step - loss: 0.2166 - accuracy: 0.9317 - val_loss: 1.6593 - val_accuracy: 0.6409\n",
            "Epoch 348/350\n",
            "100/100 [==============================] - 21s 207ms/step - loss: 0.2229 - accuracy: 0.9309 - val_loss: 1.7268 - val_accuracy: 0.6399\n",
            "Epoch 349/350\n",
            "100/100 [==============================] - 16s 155ms/step - loss: 0.2278 - accuracy: 0.9305 - val_loss: 1.6009 - val_accuracy: 0.6504\n",
            "Epoch 350/350\n",
            "100/100 [==============================] - 21s 207ms/step - loss: 0.2134 - accuracy: 0.9358 - val_loss: 1.6581 - val_accuracy: 0.6424\n",
            "313/313 [==============================] - 6s 19ms/step - loss: 1.5990 - accuracy: 0.6461\n",
            "accuracy on test set: accuracy of 64.60999846458435\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reference:\n",
        "https://github.com/LeoTungAnh/CNN-CIFAR-100    \n",
        "\n",
        "\n",
        "https://github.com/christianversloot/machine-learning-articles/blob/main/how-to-build-a-convnet-for-cifar-10-and-cifar-100-classification-with-keras.md\n"
      ],
      "metadata": {
        "id": "hXvE2X49I_AU"
      }
    }
  ]
}